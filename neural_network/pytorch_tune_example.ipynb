{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import UtilsKy\n",
    "from analyzer import AnalyzerPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch mlp for binary classification\n",
    "from numpy import vstack\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_teach = pd.read_csv( UtilsKy.DB_TEACH_KYW3, dtype=str, encoding='cp1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_test = pd.read_csv(UtilsKy.DB_TEST_KYW3, dtype=str, encoding='cp1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_FACTORS = ['amount', 'bank_currency', 'bin', 'count_months_to_end_card', 'day_of_week', 'is_city_resolved', 'hour',\n",
    "                                                             'is_gender_undefined', 'latitude', 'longitude', 'phone_2_norm']\n",
    "COL_FACTORS = sorted(COL_FACTORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import DataHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train na columns : Index(['latitude', 'longitude'], dtype='object')\n",
      "test na columns : Index(['latitude', 'longitude'], dtype='object')\n",
      "-999\n",
      "-999\n",
      "-999\n",
      "-999\n",
      "-999\n",
      "-999\n",
      "-999\n",
      "-999\n",
      "36.90237577890762\n",
      "-92.53325861542274\n",
      "-999\n"
     ]
    }
   ],
   "source": [
    "from helper import DataHelper\n",
    "datahelper = DataHelper(db_teach, db_test, COL_FACTORS)\n",
    "datahelper.create_train_test()\n",
    "datahelper.show_columns_with_na()\n",
    "mean_values = datahelper.get_mean_value()\n",
    "replaced_values = { col: mean_values[col] for col in ('latitude', 'longitude')}\n",
    "replaced_values['default'] =  -999\n",
    "datahelper.replaced_na_values(replaced_values) \n",
    "scaler_params = datahelper.get_scaler_params()\n",
    "datahelper.minMaxScaler_own()\n",
    "datahelper.add_status_in_train_test()\n",
    "train , test = datahelper.get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>bank_currency</th>\n",
       "      <th>bin</th>\n",
       "      <th>count_months_to_end_card</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_city_resolved</th>\n",
       "      <th>is_gender_undefined</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phone_2_norm</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125874</td>\n",
       "      <td>0.741749</td>\n",
       "      <td>0.032955</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.803879</td>\n",
       "      <td>0.523963</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016011</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.142897</td>\n",
       "      <td>0.046591</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571486</td>\n",
       "      <td>0.033105</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013462</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.730808</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710107</td>\n",
       "      <td>0.214711</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.132755</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.016022</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.708466</td>\n",
       "      <td>0.141195</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.083916</td>\n",
       "      <td>0.694623</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.179704</td>\n",
       "      <td>0.371303</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     amount  bank_currency       bin  count_months_to_end_card  day_of_week  \\\n",
       "0  0.000000       0.125874  0.741749                  0.032955     0.333333   \n",
       "1  0.016011       0.974359  0.142897                  0.046591     0.333333   \n",
       "2  0.013462       0.974359  0.730808                  0.050000     0.333333   \n",
       "3  0.132755       0.974359  0.016022                  0.045455     0.333333   \n",
       "4  0.000921       0.083916  0.694623                  0.090909     0.333333   \n",
       "\n",
       "       hour  is_city_resolved  is_gender_undefined  latitude  longitude  \\\n",
       "0  0.391304               1.0                  1.0  0.803879   0.523963   \n",
       "1  0.521739               1.0                  0.0  0.571486   0.033105   \n",
       "2  0.652174               0.0                  0.0  0.710107   0.214711   \n",
       "3  0.652174               1.0                  0.0  0.708466   0.141195   \n",
       "4  0.652174               1.0                  1.0  0.179704   0.371303   \n",
       "\n",
       "   phone_2_norm  status  \n",
       "0      0.555556       0  \n",
       "1      0.080808       0  \n",
       "2      0.404040       0  \n",
       "3      0.101010       0  \n",
       "4      0.191919       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>bank_currency</th>\n",
       "      <th>bin</th>\n",
       "      <th>count_months_to_end_card</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_city_resolved</th>\n",
       "      <th>is_gender_undefined</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phone_2_norm</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105304</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.018562</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.763969</td>\n",
       "      <td>0.239378</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016998</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.018502</td>\n",
       "      <td>0.053409</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730848</td>\n",
       "      <td>0.256943</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013462</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.648358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.753619</td>\n",
       "      <td>0.247821</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036531</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.648638</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.745077</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034797</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.156039</td>\n",
       "      <td>0.052273</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.710107</td>\n",
       "      <td>0.214711</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     amount  bank_currency       bin  count_months_to_end_card  day_of_week  \\\n",
       "0  0.105304       0.974359  0.018562                  0.021591     0.166667   \n",
       "1  0.016998       0.974359  0.018502                  0.053409     0.166667   \n",
       "2  0.013462       0.974359  0.648358                  0.000000     0.166667   \n",
       "3  0.036531       0.974359  0.648638                  0.039773     0.166667   \n",
       "4  0.034797       0.974359  0.156039                  0.052273     0.166667   \n",
       "\n",
       "   hour  is_city_resolved  is_gender_undefined  latitude  longitude  \\\n",
       "0   0.0               1.0                  1.0  0.763969   0.239378   \n",
       "1   0.0               1.0                  0.0  0.730848   0.256943   \n",
       "2   0.0               1.0                  1.0  0.753619   0.247821   \n",
       "3   0.0               1.0                  0.0  0.745077   0.240952   \n",
       "4   0.0               0.0                  1.0  0.710107   0.214711   \n",
       "\n",
       "   phone_2_norm  status  \n",
       "0      0.202020       0  \n",
       "1      0.232323       0  \n",
       "2      0.161616       0  \n",
       "3      0.474747       0  \n",
       "4      0.101010       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, df): # path\n",
    "        # store the inputs and outputs\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1]\n",
    "        # ensure input data is floats\n",
    "        self.X = self.X.astype('float32')\n",
    "        # label encode target and ensure the values are floats\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        self.y = self.y.astype('float32')\n",
    "        self.y = self.y.reshape((len(self.y), 1))\n",
    " \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    " \n",
    "    # get indexes for train and test rows\n",
    "    def get_splits(self, n_test=0):\n",
    "        # determine sizes\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    # define model elements\n",
    "    def __init__(self, l1=10, l2=6, n_inputs=11 ):\n",
    "        super(Net, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, l1)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # second hidden layer\n",
    "        self.hidden2 = Linear(l1, l2)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        # third hidden layer and output\n",
    "        self.hidden3 = Linear(l2, 1)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Sigmoid()\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "         # second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # third hidden layer and output\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train():\n",
    "    return train\n",
    "\n",
    "def get_validation():\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = currentdir\n",
    "checkpoint_dir = currentdir\n",
    "\n",
    "def train_nn(config, checkpoint_dir=None, data_dir=None, percent=0.05):\n",
    "    net = Net(config[\"l1\"], config[\"l2\"])        \n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    \n",
    "    # criterion for binary classification\n",
    "    criterion = BCELoss() \n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=config['momentum'])\n",
    "\n",
    "    # The `checkpoint_dir` parameter gets passed by Ray Tune when a checkpoint\n",
    "    # should be restored.\n",
    "    if checkpoint_dir:\n",
    "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "#         model_state, optimizer_state = torch.load(checkpoint)\n",
    "#         net.load_state_dict(model_state)\n",
    "#         optimizer.load_state_dict(optimizer_state)\n",
    "    \n",
    "    \n",
    "    # split train on train and validate\n",
    "    if config.get('validation'):\n",
    "        train = get_train()\n",
    "        csv_dataset = CSVDataset(train)\n",
    "        train_subset, val_subset = csv_dataset.get_splits(n_test=0.2)\n",
    "    else:\n",
    "        train = get_train()\n",
    "        train_subset = CSVDataset(train)    \n",
    "        validation = get_validation()\n",
    "        val_subset = CSVDataset(validation)    \n",
    "    \n",
    "    \n",
    "    trainloader = DataLoader( \n",
    "        train_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True)\n",
    "    \n",
    "    valloader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True)\n",
    "    \n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 10000 mini-batches\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        l_labels = []\n",
    "        l_predicted = []\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "                #==============================       \n",
    "                l_predicted += outputs[:,0].tolist()\n",
    "                l_labels += labels[:,0].tolist()\n",
    "                    \n",
    "        df = pd.DataFrame({'label': l_labels, 'predict': l_predicted})        \n",
    "        df.sort_values(by=['predict'], inplace=True, ascending=False)\n",
    "        n = int(df.shape[0] * percent)\n",
    "        n_total= sum (df.label.values)\n",
    "        p = 100*sum(df.label.values[:n])/n_total\n",
    "\n",
    "        # Here we save a checkpoint. It is automatically registered with\n",
    "        # Ray Tune and will potentially be passed as the `checkpoint_dir`\n",
    "        # parameter in future iterations.\n",
    "        with tune.checkpoint_dir(step=epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save(\n",
    "                (net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total, p_5=p)\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    train_subset = get_train()\n",
    "    trainset = CSVDataset(train_subset)    \n",
    "    \n",
    "    validation = get_validation()\n",
    "    testset = CSVDataset(validation) \n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(num_samples=10, max_num_epochs=10):\n",
    "    \n",
    "    config = {\n",
    "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([2, 4, 8, 16, 32, 64, 128]),\n",
    "        \"momentum\": tune.choice([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
    "        'validation': False\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    result = tune.run(\n",
    "        tune.with_parameters(train_nn, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 2},\n",
    "        config=config,\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    checkpoint_path = os.path.join(best_trial.checkpoint.value, \"checkpoint\")\n",
    "\n",
    "    model_state, optimizer_state = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Status ==\n",
    "# Memory usage on this node: 10.8/31.2 GiB\n",
    "# Using AsyncHyperBand: num_stopped=10 Bracket: Iter 8.000: -0.06649076655486842 | Iter 4.000: -0.06681835556443294 | Iter 2.000: -0.06733460283291567 | \n",
    "#                     Iter 1.000: -0.06842794980297343\n",
    "# Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/14.84 GiB heap, 0.0/5.08 GiB objects\n",
    "# Current best trial: ac8d2_00001 with loss=0.06682538182706561 and parameters={'l1': 32, 'l2': 4, 'lr': 0.026630467385660272, 'batch_size': 2, 'momentum': 0.1, \n",
    "#                                                                               'validation': False}\n",
    "# Result logdir: /home/sergey/ray_results/inner_2021-02-02_11-26-05\n",
    "# Number of trials: 10/10 (10 TERMINATED)\n",
    "# Trial name\tstatus\tloc\tbatch_size\tl1\tl2\tlr\tmomentum\titer\ttotal time (s)\tloss\taccuracy\tp_5\n",
    "# inner_ac8d2_00000\tTERMINATED\t\t32\t16\t128\t0.0176577\t0.7\t2\t18.6769\t0.0680945\t31.5853\t13.7748\n",
    "# inner_ac8d2_00001\tTERMINATED\t\t2\t32\t4\t0.0266305\t0.1\t10\t872.449\t0.0668254\t1.97435\t18.6755\n",
    "# inner_ac8d2_00002\tTERMINATED\t\t16\t128\t16\t0.000216925\t0.8\t1\t15.3179\t0.0703961\t15.7943\t4.76821\n",
    "# inner_ac8d2_00003\tTERMINATED\t\t128\t256\t16\t0.0128569\t0.7\t10\t52.676\t0.067173\t126.325\t18.6755\n",
    "# inner_ac8d2_00004\tTERMINATED\t\t16\t8\t32\t0.00180111\t0.3\t1\t15.2749\t0.0696522\t15.7943\t6.75497\n",
    "# inner_ac8d2_00005\tTERMINATED\t\t32\t32\t128\t0.0715262\t0.9\t1\t9.41819\t0.0678254\t31.5853\t13.1126\n",
    "# inner_ac8d2_00006\tTERMINATED\t\t128\t32\t16\t0.0135899\t0.8\t1\t4.89001\t0.0686044\t126.325\t7.41722\n",
    "# inner_ac8d2_00007\tTERMINATED\t\t8\t128\t32\t0.0808823\t0.9\t1\t28.6921\t0.0686833\t7.89718\t11.9205\n",
    "# inner_ac8d2_00008\tTERMINATED\t\t128\t16\t4\t0.000461718\t0.1\t1\t4.76229\t0.107292\t126.325\t4.23841\n",
    "# inner_ac8d2_00009\tTERMINATED\t\t64\t256\t16\t0.00907162\t0.8\t10\t60.0316\t0.0668777\t63.1653\t20.7947\n",
    "\n",
    "\n",
    "# 2021-02-02 11:40:39,295\tINFO tune.py:448 -- Total run time: 874.15 seconds (874.04 seconds for the tuning loop).\n",
    "# Best trial config: {'l1': 32, 'l2': 4, 'lr': 0.026630467385660272, 'batch_size': 2, 'momentum': 0.1, 'validation': False}\n",
    "# Best trial final validation loss: 0.06682538182706561\n",
    "# Best trial final validation accuracy: 1.9743467772077061\n",
    "# Best trial test set accuracy: 3.9486935544154123"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
