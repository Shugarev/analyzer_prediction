{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/wordcards/stock-market-tweets-wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sergey/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sergey/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sergey/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# %load _header_import.py\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('df_tweets_wordcloud/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import collections\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter        \n",
    "\n",
    "# for autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21129, 8)\n",
      "(29006, 6)\n",
      "8078\n"
     ]
    }
   ],
   "source": [
    "# %load _load_target_data.py\n",
    "path_data = '/mnt/files/workdata/work/python-scripts/prediction_analyzer/predict_stock_quotes/data/'\n",
    "\n",
    "file_old = path_data + '21K-predict.csv'\n",
    "df_old = pd.read_csv(file_old,  dtype=str)\n",
    "\n",
    "print(df_old.shape)\n",
    "# (21129, 8)\n",
    "\n",
    "file_new = path_data + 'data-2021-06-10/trainingset _1_.xlsx'\n",
    "df_new = pd.read_excel(file_new, dtype=str)\n",
    "\n",
    "print(df_new.shape)\n",
    "# (29006, 6)\n",
    "\n",
    "df_old_sub = df_old[['title', 'Unnamed: 2']].copy()\n",
    "df_old_sub.columns = ['text', 'SENTIMENT']\n",
    "\n",
    "df_new_sub = df_new[['title', 'znak']].copy()\n",
    "df_new_sub.columns = ['text', 'SENTIMENT']\n",
    "\n",
    "mask = df_new_sub['text'].isin(df_old_sub['text'])\n",
    "df_unique =  df_new_sub[~ mask].copy()\n",
    "print(df_unique.shape[0])\n",
    "\n",
    "# df_new_sub - dataset c новыми данными\n",
    "\n",
    "# df_old_sub - исходный dataset\n",
    "# df_unique - dataset с отобранными новыми данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_old_sub.shape=  21129\n",
      "df_old_sub.shape with correct sentiment=  20910\n",
      "df_new_sub.shape = 29006\n",
      "df_new_sub.shape = 28827\n",
      "df_unique.shape with correct sentiment=  7988\n",
      "df_old_sub.shape =  20910\n",
      "Counter({'positive': 9305, 'neutral': 8452, 'negative': 2937})\n",
      "df_old_sub.shape without duplicate =  20694\n",
      "df_unique.shape=  7988\n",
      "Counter({'neutral': 3545, 'positive': 3421, 'negative': 976})\n",
      "df_unique.shape without duplicate =  7942\n"
     ]
    }
   ],
   "source": [
    "# %load _prepare_sentiment_data.py\n",
    "_positive = 'positive'\n",
    "_negative = 'negative'\n",
    "_neutral = 'neutral'\n",
    "\n",
    "sentiment_list = [_neutral, _positive, _negative]\n",
    "replaced_dic = {'0': _neutral, '1': _positive, '2': _negative}\n",
    "\n",
    "#  ---df_old_sub\n",
    "df_old_sub['sentiment'] = df_old_sub['SENTIMENT'].replace(replaced_dic)\n",
    "print('df_old_sub.shape= ', df_old_sub.shape[0])\n",
    "\n",
    "mask = df_old_sub.sentiment.isin(sentiment_list)\n",
    "df_old_sub = df_old_sub[mask].copy()\n",
    "print('df_old_sub.shape with correct sentiment= ', df_old_sub.shape[0])\n",
    "\n",
    "#  ---df_new_sub\n",
    "df_new_sub['sentiment'] = df_new_sub['SENTIMENT'].replace(replaced_dic)\n",
    "print('df_new_sub.shape =', df_new_sub.shape[0])\n",
    "\n",
    "mask = df_new_sub.sentiment.isin(sentiment_list)\n",
    "df_new_sub = df_new_sub[mask].copy()\n",
    "print('df_new_sub.shape =', df_new_sub.shape[0])\n",
    "\n",
    "# ---create df_unique\n",
    "mask = df_new_sub['text'].isin(df_old_sub['text'])\n",
    "df_unique =  df_new_sub[~ mask].copy()\n",
    "\n",
    "print('df_unique.shape with correct sentiment= ', df_unique.shape[0])\n",
    "\n",
    "url_pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "\n",
    "def url(phrase):\n",
    "    return url_pattern.sub('', phrase)\n",
    "\n",
    "def prepare_data(dt: pd.DataFrame):\n",
    "    mask = dt.text.notnull()\n",
    "    dt = dt[mask].copy()\n",
    "\n",
    "    dt['text'] = dt['text'].apply(url)\n",
    "\n",
    "    dt.drop_duplicates(subset=['text'], keep='first', inplace=True)\n",
    "    print(Counter(dt['sentiment']))\n",
    "    \n",
    "    return dt\n",
    "\n",
    "# -- remove duplicate\n",
    "print('df_old_sub.shape = ', df_old_sub.shape[0])\n",
    "df_old_sub = prepare_data(df_old_sub)\n",
    "print('df_old_sub.shape without duplicate = ', df_old_sub.shape[0])\n",
    "\n",
    "print('df_unique.shape= ', df_unique.shape[0])\n",
    "df_unique = prepare_data(df_unique)\n",
    "print('df_unique.shape without duplicate = ', df_unique.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Has anyone seen this ‚ÄúRegulatory Fee?‚Äù what percentage is the fee? Can only be seen of you scroll down on a past sale order.</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Can‚Äôt sell my dogecoin? Have equity but ‚Äú0.00 available‚Äù to sell.</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>FS KKR Capital¬† declares $0.55 dividend</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Schr√∂dinger Q1 Earnings Preview</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Nuveen California AMT-Free Municipal Income Fund¬† declares $0.0545 dividend</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                 text  \\\n",
       "69   Has anyone seen this ‚ÄúRegulatory Fee?‚Äù what percentage is the fee? Can only be seen of you scroll down on a past sale order.   \n",
       "100                                                           Can‚Äôt sell my dogecoin? Have equity but ‚Äú0.00 available‚Äù to sell.   \n",
       "180                                                                                          FS KKR Capital¬† declares $0.55 dividend   \n",
       "514                                                                                                  Schr√∂dinger Q1 Earnings Preview   \n",
       "597                                                      Nuveen California AMT-Free Municipal Income Fund¬† declares $0.0545 dividend   \n",
       "\n",
       "    SENTIMENT sentiment  \n",
       "69          0   neutral  \n",
       "100         0   neutral  \n",
       "180         1  positive  \n",
       "514         1  positive  \n",
       "597         1  positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_old_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------Teach by body ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>title</th>\n",
       "      <th>znak</th>\n",
       "      <th>body</th>\n",
       "      <th>source</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22:20.6</td>\n",
       "      <td>ChipMOS misses on revenue</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seeking-alpha</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  created_at                      title znak body         source sentiment\n",
       "0    22:20.6  ChipMOS misses on revenue    2  NaN  seeking-alpha       NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29006\n",
      "11294\n"
     ]
    }
   ],
   "source": [
    "# df_new_body = df_new[['body', 'znak']].copy()\n",
    "# print(df_new_body.shape[0])\n",
    "\n",
    "# df_new_body.columns = ['text', 'SENTIMENT']\n",
    "# mask = df_new_body.text.isnull()\n",
    "\n",
    "# df_new_body = df_new_body[~mask]\n",
    "# print(df_new_body.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11248\n",
      "Counter({'positive': 4600, 'neutral': 4264, 'negative': 1441})\n",
      "10305\n"
     ]
    }
   ],
   "source": [
    "# df_new_body['sentiment'] = df_new_body['SENTIMENT'].replace(replaced_dic)\n",
    "# mask = df_new_body.sentiment.isin(sentiment_list)\n",
    "\n",
    "# df_new_body = df_new_body[mask].copy()\n",
    "# print(df_new_body.shape[0])\n",
    "\n",
    "# # -- remove duplicate\n",
    "# df_new_body = prepare_data(df_new_body)\n",
    "# print(df_new_body.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange_text(df_new_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new_body.drop(columns='text', inplace=True)\n",
    "# df_new_body.rename(columns={'text2':'text'},inplace=True)\n",
    "# df_new_body.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaced_finbert = {_positive:0, _negative:1,_neutral:2}\n",
    "# df_new_body['label'] = df_new_body['sentiment'].replace(replaced_finbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new_body.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_name:  SGDClassifier(class_weight={0: 2.2548018477996594, 1: 7.161389961389961,\n",
      "                            2: 2.3988618727366786})\n",
      "Vectorize_method:  TfidfVectorizer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.87257   0.82957   0.85053       487\n",
      "           1    0.78571   0.75342   0.76923       146\n",
      "           2    0.81542   0.87688   0.84504       398\n",
      "\n",
      "    accuracy                        0.83705      1031\n",
      "   macro avg    0.82457   0.81996   0.82160      1031\n",
      "weighted avg    0.83821   0.83705   0.83689      1031\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TfidfVectorizer(),\n",
       " SGDClassifier(class_weight={0: 2.2548018477996594, 1: 7.161389961389961,\n",
       "                             2: 2.3988618727366786}),\n",
       " array([0, 0, 2, ..., 0, 0, 1]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comppiling_model(df_new_body, SGDClassifier, vectorize_method = 'TfidfVectorizer')#, seed=34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#            0    0.86510   0.82957   0.84696       487\n",
    "#            1    0.77083   0.76027   0.76552       146\n",
    "#            2    0.81667   0.86181   0.83863       398\n",
    "\n",
    "#     accuracy                        0.83220      1031\n",
    "#    macro avg    0.81753   0.81722   0.81704      1031\n",
    "# weighted avg    0.83305   0.83220   0.83221      1031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------------------- END Teach by body ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProccess Text -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _arrange import arrange_text\n",
    "# arrange create new clear column text2!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_old_sub - исходный dataset\n",
    "# df_unique - dataset с отобранными новыми данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrange_text(df_old_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old_sub.drop(columns='text', inplace=True)\n",
    "df_old_sub.rename(columns={'text2':'text'},inplace=True)\n",
    "df_old_sub.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrange_text(df_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.drop(columns='text', inplace=True)\n",
    "df_unique.rename(columns={'text2':'text'},inplace=True)\n",
    "df_unique.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_old_sub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick view of preprocessed tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load _word_cloud.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEACHING ======================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/DrManishSharma/NLP/blob/master/SentiAnalysis.ipynb\n",
    "\n",
    "# https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "# https://github.com/scikit-learn/scikit-learn/tree/main/doc/tutorial/text_analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comppiling_model(dt: pd.DataFrame, CLS, vectorize_method: str, seed=2, threshhold=None, ngrams=1, extra_teach=None):    \n",
    "    \n",
    "    dt_train, dt_test = train_test_split(dt, test_size=0.1, random_state=seed)\n",
    "    \n",
    "    if extra_teach is not None:\n",
    "        dt_train = pd.concat([dt_train, extra_teach])\n",
    "    \n",
    "    if vectorize_method == 'CountVectorizer':\n",
    "        token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "        cv = CountVectorizer(stop_words='english', ngram_range = (ngrams, ngrams), tokenizer = token.tokenize)        \n",
    "        text_counts = cv.fit_transform(dt['text'])\n",
    "        \n",
    "        X_train =cv.transform(dt_train['text']) \n",
    "        Y_train = dt_train['label']\n",
    "        \n",
    "        X_test = cv.transform(dt_test['text']) \n",
    "        Y_test = dt_test['label']\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        tfidf = TfidfVectorizer()\n",
    "        text_counts = tfidf.fit_transform(dt_train['text'])\n",
    "        \n",
    "                   \n",
    "        X_train = tfidf.transform(dt_train['text']) \n",
    "        Y_train = dt_train['label']\n",
    "        \n",
    "        X_test = tfidf.transform(dt_test['text']) \n",
    "        Y_test = dt_test['label']\n",
    "\n",
    "        \n",
    "    n_train = dt_train.shape[0]\n",
    "    class_weight = { k:n_train/v for k,v in Counter(dt_train['label']).items() }\n",
    "    \n",
    "    cls_instance = CLS(class_weight=class_weight)\n",
    "    \n",
    "    if  CLS == GaussianNB:\n",
    "        cls_instance.fit(X_train.todense(), Y_train) \n",
    "    else:    \n",
    "        cls_instance.fit(X_train, Y_train)\n",
    "    \n",
    "    if not threshhold:\n",
    "        threshhold = 100 - Counter(Y_train)[1]/len(Y_train)*100\n",
    "    \n",
    "    threshold = 0\n",
    "    if hasattr(cls_instance, 'predict_proba') and CLS != GaussianNB:\n",
    "        predict_proba = cls_instance.predict_proba(X_test)[:,1]\n",
    "        predicted_label = np.where(predict_proba > np.percentile(predict_proba, threshhold) , 1, 0)\n",
    "        print(np.percentile(predict_proba, threshhold))\n",
    "        \n",
    "    elif hasattr(cls_instance, 'predict_proba') and CLS == GaussianNB:\n",
    "        predict_proba = cls_instance.predict_proba(X_test.todense())[:,1]\n",
    "        predicted_label = np.where(predict_proba > np.percentile(predict_proba, threshhold) , 1, 0)\n",
    "        print(np.percentile(predict_proba, threshhold))\n",
    "    else:\n",
    "        predicted_label = cls_instance.predict(X_test)  \n",
    "        \n",
    "    print('Model_name: ', cls_instance)\n",
    "    print('Vectorize_method: ', vectorize_method)\n",
    "    \n",
    "    if vectorize_method == 'CountVectorizer':\n",
    "         print('Ngrams: ', ngrams)\n",
    "    else: ngrams = 0\n",
    "    \n",
    "    print(classification_report(Y_test, predicted_label, digits=5))\n",
    "\n",
    "    information = '%s %s %s' % (cls_instance, vectorize_method, ngrams)\n",
    "\n",
    "    return tfidf, cls_instance, predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_old_sub - исходный dataset\n",
    "# df_unique - dataset с отобранными новыми данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_finbert = {_positive:0, _negative:1, _neutral:2}\n",
    "\n",
    "df_old_sub['label'] = df_old_sub['sentiment'].replace(replaced_finbert)\n",
    "df_unique['label'] = df_unique['sentiment'].replace(replaced_finbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train, dt_test = train_test_split(df_old_sub, test_size=0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9305, 2: 8452, 1: 2937})\n",
      "Counter({'positive': 9305, 'neutral': 8452, 'negative': 2937})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(df_old_sub['label']))\n",
    "print(Counter(df_old_sub['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 2.4354648881914476, 1: 7.089455652835935, 0: 2.2304191616766467}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train = dt_train.shape[0]\n",
    "class_weight_train = { k:n_train/v for k,v in Counter(dt_train['label']).items() }\n",
    "class_weight_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 5.253596614950634, 0: 5.444022215726396, 1: 19.081967213114755}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_unique = df_unique.shape[0]\n",
    "class_weight_df_unique = { k:n_train/v for k,v in Counter(df_unique['label']).items() }\n",
    "class_weight_df_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_name:  SGDClassifier(class_weight={0: 2.2569025571319346, 1: 7.373300027754649,\n",
      "                            2: 2.3736597569692637})\n",
      "Vectorize_method:  TfidfVectorizer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.85865   0.85236   0.85549       955\n",
      "           1    0.81250   0.75484   0.78261       310\n",
      "           2    0.81775   0.84720   0.83221       805\n",
      "\n",
      "    accuracy                        0.83575      2070\n",
      "   macro avg    0.82963   0.81813   0.82344      2070\n",
      "weighted avg    0.83583   0.83575   0.83552      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_idf, cls_instance, predicted_label = comppiling_model(df, SGDClassifier, vectorize_method = 'TfidfVectorizer', extra_teach=df_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_name:  SGDClassifier(class_weight={0: 2.2569025571319346, 1: 7.373300027754649,\n",
    "#                             2: 2.3736597569692637})\n",
    "# Vectorize_method:  TfidfVectorizer\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0    0.85654   0.85026   0.85339       955\n",
    "#            1    0.81185   0.75161   0.78057       310\n",
    "#            2    0.81677   0.84720   0.83171       805\n",
    "\n",
    "#     accuracy                        0.83430      2070\n",
    "#    macro avg    0.82838   0.81636   0.82189      2070\n",
    "# weighted avg    0.83438   0.83430   0.83405      2070"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comppiling_model(df, SGDClassifier, vectorize_method = 'TfidfVectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model_name:  SGDClassifier(class_weight={0: 2.2569025571319346, 1: 7.373300027754649,\n",
    "#                             2: 2.3736597569692637})\n",
    "# Vectorize_method:  TfidfVectorizer\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0    0.85654   0.85026   0.85339       955\n",
    "#            1    0.81185   0.75161   0.78057       310\n",
    "#            2    0.81677   0.84720   0.83171       805\n",
    "\n",
    "#     accuracy                        0.83430      2070\n",
    "#    macro avg    0.82838   0.81636   0.82189      2070\n",
    "# weighted avg    0.83438   0.83430   0.83405      2070"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf_idf_path = 'models/sgd_models/tf_idf_{}'.format(today)\n",
    "model_sgd_classifier_path = 'models/sgd_models/sgd_classifier_multiclass_{}'.format(today)\n",
    "\n",
    "print(model_tf_idf_path)\n",
    "print(model_sgd_classifier_path)\n",
    "# tf_idf, cls_instance, predicted_label = comppiling_model(df, SGDClassifier, vectorize_method = 'TfidfVectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# joblib.dump(tf_idf, model_tf_idf_path)\n",
    "# joblib.dump(cls_instance, model_sgd_classifier_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_old_sub - исходный dataset\n",
    "# df_unique - dataset с отобранными новыми данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_idf = joblib.load(model_tf_idf_path)\n",
    "cls_instance = joblib.load(model_sgd_classifier_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Проверка результатов сохраненной модели на тестовом сете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tf_idf.transform(dt_test['text']) \n",
    "Y_test = dt_test['label']\n",
    "\n",
    "predicted_label = cls_instance.predict(X_test)\n",
    "print(classification_report(Y_test, predicted_label, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrain the model( дообучать слабую модель смысла нет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_instance.class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf.fit_transform(df_unique['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf_idf.transform(df_unique['text']) \n",
    "Y_train = df_unique['label']\n",
    "\n",
    "X_test = tf_idf.transform(dt_test['text']) \n",
    "Y_test = dt_test['label']\n",
    "\n",
    "n_train = df_unique.shape[0]\n",
    "class_weight = { k:n_train/v for k,v in Counter(df_unique['label']).items() }\n",
    "print('class weight for df_unique =', class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_instance.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ===================================== Compare results ====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = cls_instance.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, predicted_label, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight_train\n",
    "# {1: 7.145015105740181, 0: 2.2263313609467454, 2: 2.43384298735666}\n",
    "\n",
    "# Model_name:  SGDClassifier(class_weight={0: 2.2263313609467454, 1: 7.145015105740181,\n",
    "#                             2: 2.43384298735666})\n",
    "# Vectorize_method:  TfidfVectorizer\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0    0.85125   0.83895   0.84506      1869\n",
    "#            1    0.80909   0.71774   0.76068       620\n",
    "#            2    0.80252   0.84970   0.82543      1650\n",
    "\n",
    "#     accuracy                        0.82508      4139\n",
    "#    macro avg    0.82095   0.80213   0.81039      4139\n",
    "# weighted avg    0.82551   0.82508   0.82459      4139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = [MultinomialNB, ComplementNB, GaussianNB, BernoulliNB, LinearSVC, SGDClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_predicted_label(label_positive, label_negative):\n",
    "#     if label_positive == 1 and label_negative == 0:\n",
    "#         return 1\n",
    "    \n",
    "#     if label_positive == 0 and label_negative == 1:\n",
    "#         return 2\n",
    "#     return 0\n",
    "\n",
    "# replaced_dic = {'0': _neutral, '1': _positive, '2': _negative, '3': 'unknown'}\n",
    "# replaced_dic_finbert= {_positive: 0, _neutral: 1, _negative: 2}\n",
    "# dt_test['label_num'] = dt_test['sentiment'].replace(replaced_dic_num)\n",
    "\n",
    "\n",
    "\n",
    "# all_predicted_label_num = []\n",
    "# for i in range(dt_test.shape[0]):\n",
    "#     predicted_label_num = get_predicted_label(dt_test['predicted_label_positive'].values[i], dt_test['predicted_label_negative'].values[i])\n",
    "#     all_predicted_label_num.append(predicted_label_num)\n",
    "    \n",
    "    \n",
    "# dt_test['predicted_label_num'] = all_predicted_label_num\n",
    "\n",
    "# print(Counter(dt_test['sentiment']))\n",
    "# print(Counter(dt_test['label_num'])) \n",
    "\n",
    "# print(Counter(dt_test.predicted_label_positive))\n",
    "# print(Counter(dt_test['predicted_label_num']))\n",
    "\n",
    "# print(classification_report(dt_test['label_num'].values, dt_test['predicted_label_num'].values, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [MultinomialNB, ComplementNB, GaussianNB, BernoulliNB, LinearSVC, SGDClassifier]\n",
    "\n",
    "vectorize_methods = ['CountVectorizer', 'TfidfVectorizer']\n",
    "ngrames = [1, 2, 3]\n",
    "\n",
    "all_info = []\n",
    "all_coefs = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    result = comppiling_model(df, class_name, vectorize_method = 'TfidfVectorizer')\n",
    "    all_info.append(result[0])\n",
    "    all_coefs.append(result[1])\n",
    "    for ngram in ngrames:\n",
    "        result = comppiling_model(df, class_name, vectorize_method = 'CountVectorizer', ngrams=ngram)\n",
    "        all_info.append(result[0])\n",
    "        all_coefs.append(result[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.DataFrame(all_matthews_coefs, all_info, columns=['matthew_coef']).sort_values(by='matthew_coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results without some short and stop words\n",
    "\n",
    "#### positive - MultinomialNB() TfidfVectorizer 0, matthew_coef = 0.531\n",
    "#### negative - SGDClassifier() CountVectorizer 3, matthew_coef = 0.399\n",
    "#### neutral -  MultinomialNB() TfidfVectorizer 0, matthew_coef = 0.471"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {'pred': predict_proba, 'label':Y_test }\n",
    "# tmp = pd.DataFrame(data)\n",
    "# tmp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://127.0.0.1:8000/api/v0/predict'\n",
    "payload = '{\"text\": \"good news\"}' \n",
    "headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
    "\n",
    "response = requests.post(url, data=payload, headers=headers)\n",
    "json_data = json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentiment_title = []\n",
    "all_sentiment_score_title = []\n",
    "for title in df_sub['text'].values:\n",
    "#     print(title)\n",
    "\n",
    "    payload = json.dumps({\"text\": title}) \n",
    "\n",
    "    response = requests.post(url, data=payload, headers=headers)\n",
    "    json_data = json.loads(response.text)\n",
    "#     print(json_data)    \n",
    "    all_sentiment_title.append(json_data['sentiment'])\n",
    "    all_sentiment_score_title.append(json_data['sentiment_score'])\n",
    "\n",
    "df_sub['pred_sentiment_title']  = all_sentiment_title\n",
    "df_sub['pred_sentiment_score_title']  = all_sentiment_score_title    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentiment_title = []\n",
    "all_sentiment_score_title = []\n",
    "for title in df_sub['text_back'].values:\n",
    "#     print(title)\n",
    "\n",
    "    payload = json.dumps({\"text\": title}) \n",
    "\n",
    "    response = requests.post(url, data=payload, headers=headers)\n",
    "    json_data = json.loads(response.text)\n",
    "#     print(json_data)    \n",
    "    all_sentiment_title.append(json_data['sentiment'])\n",
    "    all_sentiment_score_title.append(json_data['sentiment_score'])\n",
    "    \n",
    "df_sub['back_pred_sentiment_title']  = all_sentiment_title\n",
    "df_sub['back_pred_sentiment_score_title']  = all_sentiment_score_title\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['back_pred_sentiment_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['sentiment'].value_counts()/df_sub.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['pred_sentiment_title'].value_counts()/df_sub.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_sub, test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.where(test.sentiment == _neutral, 1, 0)\n",
    "predicted_label = np.where(test.back_pred_sentiment_title == _neutral, 1, 0)\n",
    "print(classification_report(label, predicted_label, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"text\":['djlfjlsajdfla']} \n",
    "dt = pd.DataFrame(d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import numpy as np\n",
    ">>> from sklearn.linear_model import SGDClassifier\n",
    ">>> from sklearn.preprocessing import StandardScaler\n",
    ">>> from sklearn.pipeline import make_pipeline\n",
    ">>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1],[-1, 51]])\n",
    ">>> Y = np.array([1, 0, 2, 0,1])\n",
    ">>> # Always scale the input. The most convenient way is to use a pipeline.\n",
    ">>> clf = make_pipeline(StandardScaler(),\n",
    "...                     SGDClassifier(max_iter=1000, tol=1e-3))\n",
    ">>> clf.fit(X, Y)\n",
    "\n",
    ">>> print(clf.predict([[-2, -1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
